#version 450

#extension GL_GOOGLE_include_directive : require

layout(local_size_x = 4, local_size_y = 4, local_size_z = 4) in;

layout(set = 0, binding = 0) readonly buffer B_ContreeBuildState {
    uint prev_dim;
    uint curr_dim;
    uint level;
}
contree_build_state;

layout(set = 0, binding = 1, r32ui) readonly uniform uimage3D frag_img;

layout(set = 0, binding = 2) readonly buffer B_NodeOffsetForLevels { uint data[]; }
node_offset_for_levels;

#include "../../include/contree_node.glsl"
layout(set = 0, binding = 3) writeonly buffer B_SparseNodes { ContreeNode data[]; }
sparse_nodes;

layout(set = 0, binding = 4) writeonly buffer B_LeafData { uint data[]; }
leaf_data;

layout(set = 0, binding = 5) writeonly buffer B_ContreeBuildResult {
    uint node_len;
    uint leaf_len;
}
contree_build_result;

#include "../../include/core/bits.glsl"

shared uint workgroup_cnt[64];
shared uint prefix_sums[64];
shared uint group_base;

void main() {
    ivec3 uvi = ivec3(gl_GlobalInvocationID);
    if (any(greaterThanEqual(uvi, ivec3(contree_build_state.curr_dim)))) {
        return;
    }

    uint temp[64];
    uint64_t child_mask = 0;
    for (uint yi = 0; yi < 4; yi++) {
        for (uint zi = 0; zi < 4; zi++) {
            for (uint xi = 0; xi < 4; xi++) {
                uint i = xi + zi * 4 + yi * 16;

                ivec3 vpos = uvi * 4 + ivec3(xi, yi, zi);
                uint v     = imageLoad(frag_img, vpos).x;
                temp[i]    = v;

                // the node is valid if voxel type is non zero
                bool exists = (v != 0);
                child_mask |= exists ? (uint64_t(1) << i) : 0ul;
            }
        }
    }

    uint cnt = bit_count_u64(child_mask);

    // MARK:

    uint local_id           = gl_LocalInvocationIndex;
    workgroup_cnt[local_id] = cnt;
    barrier();

    if (local_id == 0) {
        prefix_sums[0] = 0;
        // Initialize the prefix sum array to zero
        for (uint i = 1; i < 64; ++i) {
            prefix_sums[i] = prefix_sums[i - 1] + workgroup_cnt[i - 1];
        }
        uint group_cnt = prefix_sums[63] + workgroup_cnt[63];

        group_base = atomicAdd(contree_build_result.leaf_len, group_cnt);
    }
    barrier();

    uint local_base = prefix_sums[local_id];
    uint base       = group_base + local_base;

    // MARK:

    uint sparse_node_write_offset = node_offset_for_levels.data[contree_build_state.level];
    uint brick_idx                = uint(uvi.x) + uint(uvi.z) * contree_build_state.curr_dim +
                     uint(uvi.y) * contree_build_state.curr_dim * contree_build_state.curr_dim;
    brick_idx += sparse_node_write_offset;

    // early out: if no voxels are presented in this brick
    if (cnt == 0) {
        sparse_nodes.data[brick_idx].packed_0   = 0;
        sparse_nodes.data[brick_idx].child_mask = 0ul;
        return;
    }

    // If there are valid voxels, write their data to the leaf_data buffer.
    // 'w' tracks the number of voxels written by this invocation.
    uint w = 0;
    for (uint i = 0; i < 64; i++) {
        // Check if the i-th voxel in the 4x4x4 brick is valid.
        if ((child_mask & (uint64_t(1) << i)) != 0) {
            leaf_data.data[base + w] = temp[i];
            w++;
        }
    }

    // because we are using 31 bits for the leaf ptr, there's a limit of 1290^3 of total voxels pre
    // chunk
    // 1290^3 = 2146689000, 2^31 = 2147483648, so we are safe
    // so the maximum available voxel dim limit is 1024^3, to match the 4^n dimension need of
    // contree
    sparse_nodes.data[brick_idx].packed_0   = 1 | (base << 1);
    sparse_nodes.data[brick_idx].child_mask = child_mask;
}
